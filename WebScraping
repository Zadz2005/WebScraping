{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKc15w0baUJMOR9QbjJjND"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from io import StringIO\n",
        "import time\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "standings_url = \"https://kworb.net/spotify/\"\n",
        "data = requests.get(standings_url)\n",
        "soup = BeautifulSoup(data.text, \"html.parser\")\n",
        "standings_table = soup.select('table[style=\"width: 410px;\"]')[0]\n",
        "\n",
        "links = [l.get(\"href\") for l in standings_table.find_all('a')]\n",
        "links = [l for l in links if 'weekly_total' in l]\n",
        "Countries = [f\"https://kworb.net/spotify/{l}\" for l in links]\n",
        "\n",
        "\n",
        "country_rows = []\n",
        "artist_rows = []\n",
        "\n",
        "for country_url in Countries[:7]:\n",
        "    country_name = country_url.split(\"/\")[-1].replace(\"_\", \" \").replace(\".html\", \"\")\n",
        "    print(f\"🌍 Processing {country_name}...\")\n",
        "\n",
        "    try:\n",
        "\n",
        "        data = requests.get(country_url)\n",
        "        html = StringIO(data.text)\n",
        "        top_chart = pd.read_html(html, match=\"Artist and Title\")[0].head(10)\n",
        "\n",
        "\n",
        "        for rank, row in top_chart.iterrows():\n",
        "            country_rows.append({\n",
        "                \"country_name\": country_name,\n",
        "                \"rank\": rank + 1,\n",
        "                \"artist_name\": row[\"Artist and Title\"]\n",
        "            })\n",
        "\n",
        "\n",
        "        country_soup = BeautifulSoup(data.text, \"html.parser\")\n",
        "        rows = country_soup.select(\"table tr\")[1:11]\n",
        "        artist_links = []\n",
        "        for row in rows:\n",
        "            a = row.find(\"a\", href=True)\n",
        "            if a and \"artist\" in a[\"href\"]:\n",
        "                link = f\"https://kworb.net/spotify{a['href'].replace('..','')}\"\n",
        "                artist_links.append(link)\n",
        "\n",
        "        for i, artist_url in enumerate(artist_links[:10]):\n",
        "            try:\n",
        "                artist_name = top_chart.iloc[i][\"Artist and Title\"]\n",
        "                artist_data = requests.get(artist_url)\n",
        "                artist_html = StringIO(artist_data.text)\n",
        "                details_df = pd.read_html(artist_html, match=\"Peak Date\")[0]\n",
        "\n",
        "\n",
        "                for _, drow in details_df.head(10).iterrows():\n",
        "                    artist_rows.append({\n",
        "                        \"country_name\": country_name,\n",
        "                        \"artist_name\": artist_name,\n",
        "                        **drow.to_dict()\n",
        "                    })\n",
        "\n",
        "                print(f\"    {artist_name} details collected\")\n",
        "                time.sleep(1)\n",
        "            except Exception as e:\n",
        "                print(f\"   ⚠️ Could not fetch artist {i} in {country_name}: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Could not fetch country {country_name}: {e}\")\n",
        "\n",
        "\n",
        "country_df = pd.DataFrame(country_rows)\n",
        "artist_details_df = pd.DataFrame(artist_rows)\n",
        "\n",
        "country_df.to_csv(\"country_top10.csv\", index=False)\n",
        "artist_details_df.to_csv(\"artist_details.csv\", index=False)\n",
        "\n",
        "print(\" All CSVs saved\")\n",
        "\n",
        "\n",
        "files.download(\"country_top10.csv\")\n",
        "files.download(\"artist_details.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YMLwGR2hV6C6",
        "outputId": "c68534aa-7b31-4366-e907-185fdf32c82c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌍 Processing global weekly totals...\n",
            "   ✅ The Weeknd - Blinding Lights details collected\n",
            "   ✅ Ed Sheeran - Shape of You details collected\n",
            "   ✅ Harry Styles - As It Was details collected\n",
            "   ✅ Lewis Capaldi - Someone You Loved details collected\n",
            "   ✅ Post Malone - Sunflower - Spider-Man: Into the Spider-Verse details collected\n",
            "   ✅ The Neighbourhood - Sweater Weather details collected\n",
            "   ✅ Billie Eilish - lovely details collected\n",
            "   ✅ Imagine Dragons - Believer details collected\n",
            "   ✅ The Kid LAROI - Stay details collected\n",
            "   ✅ Ed Sheeran - Perfect details collected\n",
            "🌍 Processing us weekly totals...\n",
            "   ✅ J. Cole - No Role Modelz details collected\n",
            "   ✅ Post Malone - Sunflower - Spider-Man: Into the Spider-Verse details collected\n",
            "   ✅ The Neighbourhood - Sweater Weather details collected\n",
            "   ✅ Juice WRLD - Lucid Dreams details collected\n",
            "   ✅ Kendrick Lamar - HUMBLE. details collected\n",
            "   ✅ Tyler, The Creator - See You Again details collected\n",
            "   ✅ Morgan Wallen - Last Night details collected\n",
            "   ✅ Lil Uzi Vert - XO TOUR Llif3 details collected\n",
            "   ✅ Zach Bryan - Something in the Orange details collected\n",
            "   ✅ Travis Scott - goosebumps details collected\n",
            "🌍 Processing gb weekly totals...\n",
            "   ✅ The Killers - Mr. Brightside details collected\n",
            "   ✅ Lewis Capaldi - Someone You Loved details collected\n",
            "   ✅ Vance Joy - Riptide details collected\n",
            "   ✅ Drake - One Dance details collected\n",
            "   ✅ The Weeknd - Blinding Lights details collected\n",
            "   ✅ Arctic Monkeys - Do I Wanna Know? details collected\n",
            "   ✅ Oasis - Wonderwall - Remastered details collected\n",
            "   ✅ Ed Sheeran - Shape of You details collected\n",
            "   ✅ Hozier - Take Me To Church details collected\n",
            "   ✅ Mariah Carey - All I Want for Christmas Is You details collected\n",
            "🌍 Processing ad weekly totals...\n",
            "   ✅ Luis Fonsi - Despacito (Featuring Daddy Yankee) details collected\n",
            "   ✅ Ed Sheeran - Shape of You details collected\n",
            "   ✅ C. Tangana - TÃº Me Dejaste De Querer details collected\n",
            "   ✅ Maluma - HawÃ¡i details collected\n",
            "   ✅ Bad Bunny - DÃKITI details collected\n",
            "   ✅ Sech - RelaciÃ³n - Remix details collected\n",
            "   ✅ Manuel Turizo - La Nota details collected\n",
            "   ✅ Enrique Iglesias - SUBEME LA RADIO details collected\n",
            "   ✅ Bad Bunny - Dakiti details collected\n",
            "   ✅ Bad Bunny - LA NOCHE DE ANOCHE details collected\n",
            "🌍 Processing ar weekly totals...\n",
            "   ✅ Manuel Turizo - La Bachata details collected\n",
            "   ✅ Luck Ra - Ya No Vuelvas (VersiÃ³n Cuarteto) details collected\n",
            "   ✅ Big One - Un Finde | CROSSOVER #2 details collected\n",
            "   ✅ TINI - MiÃ©nteme details collected\n",
            "   ✅ Luck Ra - La Morocha details collected\n",
            "   ✅ Bizarrap - Quevedo: Bzrp Music Sessions, Vol. 52 details collected\n",
            "   ✅ No Te Va Gustar - A las Nueve details collected\n",
            "   ✅ Big One - En la Intimidad details collected\n",
            "   ✅ Airbag - Por Mil Noches details collected\n",
            "   ✅ Luck Ra - QUE ME FALTE TODO details collected\n",
            "🌍 Processing au weekly totals...\n",
            "   ✅ The Killers - Mr. Brightside details collected\n",
            "   ✅ Vance Joy - Riptide details collected\n",
            "   ✅ Glass Animals - Heat Waves details collected\n",
            "   ✅ Lewis Capaldi - Someone You Loved details collected\n",
            "   ✅ Post Malone - Sunflower - Spider-Man: Into the Spider-Verse details collected\n",
            "   ✅ The Weeknd - Blinding Lights details collected\n",
            "   ✅ Fleetwood Mac - Dreams - 2004 Remaster details collected\n",
            "   ✅ The Kid LAROI - Stay details collected\n",
            "   ✅ James Arthur - Say You Won't Let Go details collected\n",
            "   ✅ Ed Sheeran - Shape of You details collected\n",
            "🌍 Processing at weekly totals...\n",
            "   ✅ Tom Odell - Another Love details collected\n",
            "   ✅ Bonez MC - Ohne mein Team details collected\n",
            "   ✅ Apache 207 - Roller details collected\n",
            "   ✅ Mariah Carey - All I Want for Christmas Is You details collected\n",
            "   ✅ Wham! - Last Christmas details collected\n",
            "   ✅ Vance Joy - Riptide details collected\n",
            "   ✅ The Weeknd - Blinding Lights details collected\n",
            "   ✅ Bonez MC - 500 PS details collected\n",
            "   ✅ Glass Animals - Heat Waves details collected\n",
            "   ✅ The Neighbourhood - Sweater Weather details collected\n",
            "✅ All CSVs saved\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f58c6d2d-92d8-4876-bec8-b18f37eec0eb\", \"country_top10.csv\", 3521)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_47288eff-0973-47b4-a175-17b983e090d2\", \"artist_details.csv\", 193768)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dyrAHlSBoSCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "13Apc6wH2qmV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}